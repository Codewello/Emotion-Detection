{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1: Importing the required libraries\n",
        "\n",
        "we going to need keras , numpy , sklearn, pandas , nltk\n",
        "\n"
      ],
      "metadata": {
        "id": "EEmOA_dn98IC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jay5udIrd0V",
        "outputId": "e98ac495-0b9a-4ac4-dfb7-dc8c9213ca59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "\n",
        "# Importing the required libraries\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense,Bidirectional\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from keras.layers import *\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import nltk\n",
        "import pandas as pd\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2- Loading our dataset\n",
        " isear - International Survey on Emotion Antecedents and Reactions\n",
        "\n",
        "\n",
        " and chaning the names of the columns\n"
      ],
      "metadata": {
        "id": "3P5w7INS_fdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/isear.csv',header=None)\n",
        "# Rename columns and reorder them\n",
        "df.columns = ['emotion', 'text']\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TKa1xk3BtP-3",
        "outputId": "6056f444-03ca-401c-f5a2-2dedfe9c4dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   emotion                                               text\n",
              "0      joy  [ On days when I feel close to my partner and ...\n",
              "1     fear  Every time I imagine that someone I love or I ...\n",
              "2    anger  When I had been obviously unjustly treated and...\n",
              "3  sadness  When I think about the short time that we live...\n",
              "4  disgust  At a gathering I found myself involuntarily si..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-345b84a2-0ae1-4728-9c2d-88943b328ce7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>joy</td>\n",
              "      <td>[ On days when I feel close to my partner and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fear</td>\n",
              "      <td>Every time I imagine that someone I love or I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>anger</td>\n",
              "      <td>When I had been obviously unjustly treated and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sadness</td>\n",
              "      <td>When I think about the short time that we live...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>disgust</td>\n",
              "      <td>At a gathering I found myself involuntarily si...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-345b84a2-0ae1-4728-9c2d-88943b328ce7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-345b84a2-0ae1-4728-9c2d-88943b328ce7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-345b84a2-0ae1-4728-9c2d-88943b328ce7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fa37ec72-5f67-42b4-94a8-25c6206e434c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa37ec72-5f67-42b4-94a8-25c6206e434c')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fa37ec72-5f67-42b4-94a8-25c6206e434c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "2fYI8mbvtZpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd38f916-b461-4744-bca3-e3572fb87dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 7575 entries, 0 to 7651\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   emotion  7575 non-null   object\n",
            " 1   text     7575 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 435.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "drop the null data \"No Response.\" from text column"
      ],
      "metadata": {
        "id": "uytByukNA_Vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noResponse = df[df['text'] == '[ No response.]'].index\n",
        "df.drop(noResponse, inplace=True)"
      ],
      "metadata": {
        "id": "u8yGL0CFtiqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3:  Tokeization\n",
        "\n",
        "Apply a word tokenizer to convert each sentence into a list of words.\n",
        "\n",
        "ex : if  sentence- ‘I am sad. after tokenizing it will get converted into a list [‘I’,’am’, sad]."
      ],
      "metadata": {
        "id": "8eMMXYHCDcg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#select the text column\n",
        "emotion_arr=df['text']\n",
        "\n",
        "#first row\n",
        "emotion_arr[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "IUW3O9aSumki",
        "outputId": "26144e41-8360-4cdb-aa32-5326bc73cf1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[ On days when I feel close to my partner and other friends.  \\nWhen I feel at peace with myself and also experience a close \\ncontact with people whom I regard greatly.]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loop over the text using word_tokenize\n",
        "emotion_arr=[word_tokenize(sent) for sent in emotion_arr]\n",
        "print(emotion_arr[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU-WVtnKvUvE",
        "outputId": "f0563685-4f39-4b23-aa35-7c9737114068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[', 'On', 'days', 'when', 'I', 'feel', 'close', 'to', 'my', 'partner', 'and', 'other', 'friends', '.', 'When', 'I', 'feel', 'at', 'peace', 'with', 'myself', 'and', 'also', 'experience', 'a', 'close', 'contact', 'with', 'people', 'whom', 'I', 'regard', 'greatly', '.', ']']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 4: Padding\n",
        "Padding in NLP (Natural Language Processing) is like adding extra spaces or symbols to make all sentences in a dataset have the same length."
      ],
      "metadata": {
        "id": "6iUWwXOmCqXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defined a function padd in which each sentence length is fixed to 100.\n",
        "# If length is less than 100 , then the word- '<padd>' is append\n",
        "def padd(arr):\n",
        "    for i in range(100-len(arr)):\n",
        "        arr.append('<pad>')\n",
        "    return arr[:100]\n",
        "\n",
        "# call the padd function for each sentence in emotion_arr\n",
        "for i in range(len(emotion_arr)):\n",
        "  emotion_arr[i]=padd(emotion_arr[i])"
      ],
      "metadata": {
        "id": "vJOvu2VBvaq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(emotion_arr[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-UuvH4tvp-z",
        "outputId": "21cff4c2-ef51-4b46-ba79-ff4c07360b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[', 'On', 'days', 'when', 'I', 'feel', 'close', 'to', 'my', 'partner', 'and', 'other', 'friends', '.', 'When', 'I', 'feel', 'at', 'peace', 'with', 'myself', 'and', 'also', 'experience', 'a', 'close', 'contact', 'with', 'people', 'whom', 'I', 'regard', 'greatly', '.', ']', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to my Google Drive."
      ],
      "metadata": {
        "id": "VJISoNIMDAzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PerqBd9HwuuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5:Word embedding using the glove\n",
        "\n",
        "Each word needs a numeric representation for the model to understand it, as the model only works with numbers. To do this, we got a ready-made set of 50-number vectors called \"GloVe vectors\" from the internet. These vectors help convert words into these 50-number representations.\n",
        "\n",
        "The GloVe vector collection covers nearly all English words.\n",
        "\n",
        "In each row, the first word is the one we're converting into numbers. The remaining columns in that row correspond to the 50 numbers in the vector."
      ],
      "metadata": {
        "id": "FAnGOWSXDOdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_f ='/content/glove.6B.50d.txt'"
      ],
      "metadata": {
        "id": "F6tBdzjHw1Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# embeddings_index is a dictionary which contains the mapping of\n",
        "# word with its corresponding 50d vector.\n",
        "embeddings_index = {}\n",
        "with open(vocab_f, encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        # splitting each line of the glove.6B.50d in a list of\n",
        "        # items- in which the first element is the word to be embedded,\n",
        "        # and from second to the end of line contains the 50d vector.\n",
        "        values = line.rstrip().rsplit(' ')\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "# the embedding index of word 'happy'\n",
        "embeddings_index['happy']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oprx8wl6w8i5",
        "outputId": "e0a6bed9-5797-45c1-d439-bed87ed56e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.092086,  0.2571  , -0.58693 , -0.37029 ,  1.0828  , -0.55466 ,\n",
              "       -0.78142 ,  0.58696 , -0.58714 ,  0.46318 , -0.11267 ,  0.2606  ,\n",
              "       -0.26928 , -0.072466,  1.247   ,  0.30571 ,  0.56731 ,  0.30509 ,\n",
              "       -0.050312, -0.64443 , -0.54513 ,  0.86429 ,  0.20914 ,  0.56334 ,\n",
              "        1.1228  , -1.0516  , -0.78105 ,  0.29656 ,  0.7261  , -0.61392 ,\n",
              "        2.4225  ,  1.0142  , -0.17753 ,  0.4147  , -0.12966 , -0.47064 ,\n",
              "        0.3807  ,  0.16309 , -0.323   , -0.77899 , -0.42473 , -0.30826 ,\n",
              "       -0.42242 ,  0.055069,  0.38267 ,  0.037415, -0.4302  , -0.39442 ,\n",
              "        0.10511 ,  0.87286 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Embedding each word of the emotion_arr\n",
        "embedded_emotion_arr = []\n",
        "\n",
        "for each_sentence in emotion_arr:\n",
        "    embedded_emotion_arr.append([])\n",
        "    for word in each_sentence:\n",
        "        if word.lower() in embeddings_index:\n",
        "            embedded_emotion_arr[-1].append(embeddings_index[word.lower()])\n",
        "        else:\n",
        "            # if the word to be embedded is '<padd>' append 0 fifty times\n",
        "            embedded_emotion_arr[-1].append([0]*50)\n",
        "\n",
        "print(embedded_emotion_arr[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYOpJpz00OSa",
        "outputId": "27e91892-2764-45c6-8836-240835cb33f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.61201   0.98226   0.11539   0.014623  0.23873  -0.067035  0.30632\n",
            " -0.64742  -0.38517  -0.03691   0.094788  0.57631  -0.091557 -0.54825\n",
            "  0.25255  -0.14759   0.13023   0.21658  -0.30623   0.30028  -0.23471\n",
            " -0.17927   0.9518    0.54258   0.31172  -0.51038  -0.65223  -0.48858\n",
            "  0.13486  -0.40132   2.493    -0.38777  -0.26456  -0.49414  -0.3871\n",
            " -0.20983   0.82941  -0.46253   0.39549   0.014881  0.79485  -0.79958\n",
            " -0.16243   0.013862 -0.53536   0.52536   0.019818 -0.16353   0.30649\n",
            "  0.81745 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6: One Hot encoding for the target variables and split train and test dataset\n",
        "\n",
        "Do one-hot encoding of each emotion.\n",
        "\n",
        "Split the dataset into train and test sets."
      ],
      "metadata": {
        "id": "TVAoVWsKHA8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform one-hot encoding from sklearn\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "Y = enc.fit_transform(np.array(df['emotion']).reshape(-1,1)).toarray()\n",
        "X=np.array(embedded_emotion_arr)\n"
      ],
      "metadata": {
        "id": "8NKJPavH0XCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Split into train and test\n",
        "from keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "QnhTslxuVOWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create model\n",
        "\n",
        "\n",
        "\n",
        "  ```\n",
        "  def model(X, Y, input_size1, input_size2, output_size)\n",
        "  ```\n",
        "  :: This is the function definition that takes input data (X), target labels (Y), input size dimensions (input_size1 and input_size2), and output size (output_size) as parameters.\n",
        "  ```\n",
        "  m = Sequential()\n",
        "  ```\n",
        "  :Creates a Sequential model, which is a linear stack of layers.\n",
        "  ```\n",
        "  m.add(Bidirectional(LSTM(100, input_shape=(input_size1, input_size2))))\n",
        "  ```\n",
        "\n",
        "  Adds a Bidirectional LSTM layer with 100 units to the model. The input_shape parameter specifies the shape of the input data.\n",
        "  ```\n",
        "  m.add(Dropout(0.5))\n",
        "  ```\n",
        "  Adds a dropout layer that randomly drops 50% of the connections to prevent overfitting.\n",
        "\n",
        "  ```\n",
        "  m.add(Dense(output_size, activation='softmax'))\n",
        "  ```\n",
        "  Adds a fully connected Dense layer with a size of output_size units and a softmax activation function, which is often used for multi-class classification problems.\n",
        "\n",
        "  ```\n",
        "  m.compile('Adam', 'categorical_crossentropy', ['accuracy'])\n",
        "  ```\n",
        "  Compiles the model with the Adam optimizer, categorical cross-entropy loss (suitable for multiclass classification), and accuracy metric.\n",
        "\n",
        "  ```\n",
        "  m.fit(X, Y, epochs=32, batch_size=128)\n",
        "  ```\n",
        "  Trains the model on the input data X and target labels Y for 32 epochs using batches of size 128.\n",
        "  ```\n",
        "  return m\n",
        "  ```\n",
        "  Returns the compiled and trained model."
      ],
      "metadata": {
        "id": "z2J1tpxdHrvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the BiLSTM Model\n",
        "def model(X, Y, input_size1, input_size2, output_size):\n",
        "    m = Sequential()  # Create a Sequential model\n",
        "\n",
        "    # Add a Bidirectional LSTM layer with 100 units\n",
        "    m.add(Bidirectional(LSTM(100, input_shape=(input_size1, input_size2))))\n",
        "\n",
        "    m.add(Dropout(0.5))  # Add a dropout layer with 50% dropout rate\n",
        "\n",
        "    # Add a Dense (fully connected) layer with 'output_size' units and softmax activation\n",
        "    m.add(Dense(output_size, activation='softmax'))\n",
        "\n",
        "    # Compile the model with 'Adam' optimizer, 'categorical_crossentropy' loss, and 'accuracy' metric\n",
        "    m.compile('Adam', 'categorical_crossentropy', ['accuracy'])\n",
        "\n",
        "    # Train the model on input data 'X' and target labels 'Y' for 32 epochs, using batches of size 128\n",
        "    m.fit(X, Y, epochs=32, batch_size=128)\n",
        "\n",
        "    return m  # Return the compiled and trained model\n"
      ],
      "metadata": {
        "id": "t7QKkPovHq6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bilstmModel=model(X_train,Y_train,100,50,7)"
      ],
      "metadata": {
        "id": "MjExxKAp1B3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf257f40-ffc4-4a92-c336-5dcd2cb31b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "48/48 [==============================] - 35s 605ms/step - loss: 1.9187 - accuracy: 0.1957\n",
            "Epoch 2/32\n",
            "48/48 [==============================] - 24s 500ms/step - loss: 1.7789 - accuracy: 0.3119\n",
            "Epoch 3/32\n",
            "48/48 [==============================] - 25s 508ms/step - loss: 1.6928 - accuracy: 0.3523\n",
            "Epoch 4/32\n",
            "48/48 [==============================] - 25s 524ms/step - loss: 1.6610 - accuracy: 0.3658\n",
            "Epoch 5/32\n",
            "48/48 [==============================] - 22s 469ms/step - loss: 1.6105 - accuracy: 0.3850\n",
            "Epoch 6/32\n",
            "48/48 [==============================] - 26s 551ms/step - loss: 1.5916 - accuracy: 0.3919\n",
            "Epoch 7/32\n",
            "48/48 [==============================] - 24s 499ms/step - loss: 1.5655 - accuracy: 0.4035\n",
            "Epoch 8/32\n",
            "48/48 [==============================] - 23s 478ms/step - loss: 1.5344 - accuracy: 0.4271\n",
            "Epoch 9/32\n",
            "48/48 [==============================] - 25s 515ms/step - loss: 1.4978 - accuracy: 0.4429\n",
            "Epoch 10/32\n",
            "48/48 [==============================] - 22s 464ms/step - loss: 1.4677 - accuracy: 0.4592\n",
            "Epoch 11/32\n",
            "48/48 [==============================] - 25s 520ms/step - loss: 1.4657 - accuracy: 0.4573\n",
            "Epoch 12/32\n",
            "48/48 [==============================] - 22s 466ms/step - loss: 1.4162 - accuracy: 0.4818\n",
            "Epoch 13/32\n",
            "48/48 [==============================] - 24s 510ms/step - loss: 1.3916 - accuracy: 0.4861\n",
            "Epoch 14/32\n",
            "48/48 [==============================] - 24s 500ms/step - loss: 1.3708 - accuracy: 0.4987\n",
            "Epoch 15/32\n",
            "48/48 [==============================] - 23s 474ms/step - loss: 1.3399 - accuracy: 0.5134\n",
            "Epoch 16/32\n",
            "48/48 [==============================] - 25s 525ms/step - loss: 1.3219 - accuracy: 0.5140\n",
            "Epoch 17/32\n",
            "48/48 [==============================] - 22s 467ms/step - loss: 1.3108 - accuracy: 0.5175\n",
            "Epoch 18/32\n",
            "48/48 [==============================] - 25s 522ms/step - loss: 1.2589 - accuracy: 0.5404\n",
            "Epoch 19/32\n",
            "48/48 [==============================] - 23s 471ms/step - loss: 1.2612 - accuracy: 0.5396\n",
            "Epoch 20/32\n",
            "48/48 [==============================] - 26s 536ms/step - loss: 1.2539 - accuracy: 0.5488\n",
            "Epoch 21/32\n",
            "48/48 [==============================] - 25s 522ms/step - loss: 1.2265 - accuracy: 0.5508\n",
            "Epoch 22/32\n",
            "48/48 [==============================] - 24s 492ms/step - loss: 1.1917 - accuracy: 0.5607\n",
            "Epoch 23/32\n",
            "48/48 [==============================] - 26s 528ms/step - loss: 1.1759 - accuracy: 0.5743\n",
            "Epoch 24/32\n",
            "48/48 [==============================] - 26s 547ms/step - loss: 1.1567 - accuracy: 0.5800\n",
            "Epoch 25/32\n",
            "48/48 [==============================] - 22s 465ms/step - loss: 1.1301 - accuracy: 0.5876\n",
            "Epoch 26/32\n",
            "48/48 [==============================] - 25s 522ms/step - loss: 1.1233 - accuracy: 0.5916\n",
            "Epoch 27/32\n",
            "48/48 [==============================] - 22s 469ms/step - loss: 1.1010 - accuracy: 0.5977\n",
            "Epoch 28/32\n",
            "48/48 [==============================] - 27s 555ms/step - loss: 1.0877 - accuracy: 0.6041\n",
            "Epoch 29/32\n",
            "48/48 [==============================] - 26s 550ms/step - loss: 1.0716 - accuracy: 0.6124\n",
            "Epoch 30/32\n",
            "48/48 [==============================] - 23s 474ms/step - loss: 1.0539 - accuracy: 0.6175\n",
            "Epoch 31/32\n",
            "48/48 [==============================] - 25s 518ms/step - loss: 1.0417 - accuracy: 0.6215\n",
            "Epoch 32/32\n",
            "48/48 [==============================] - 28s 578ms/step - loss: 0.9986 - accuracy: 0.6384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7: save the model\n"
      ],
      "metadata": {
        "id": "TgWD5zCqSF_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6GBNC5TT-LXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bilstmModel.summary()"
      ],
      "metadata": {
        "id": "B-4enI4O1H_r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc9e0f7-9f1c-4f0b-d920-09eb616a3f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_1 (Bidirectio  (None, 200)              120800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 1407      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122,207\n",
            "Trainable params: 122,207\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the model\n",
        "bilstmModel.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "K5aXQbBg401w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64b902c9-f1a4-4ad9-cdeb-51902ff7013d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48/48 [==============================] - 3s 40ms/step - loss: 1.5878 - accuracy: 0.4528\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.587786078453064, 0.4528052806854248]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8 : predict using our model"
      ],
      "metadata": {
        "id": "U-d8bN1vSRp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess input text for prediction\n",
        "def preprocess_input_text(text):\n",
        "    tokenized_text = word_tokenize(text)\n",
        "    padded_text = padd(tokenized_text)\n",
        "\n",
        "    embedded_text = []\n",
        "    for word in padded_text:\n",
        "        if word.lower() in embeddings_index:\n",
        "            embedded_text.append(embeddings_index[word.lower()])\n",
        "        else:\n",
        "            embedded_text.append([0]*50)\n",
        "    return np.array(embedded_text)\n"
      ],
      "metadata": {
        "id": "pmS2Hyk349_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"I am feeling happy today.\"\n",
        "processed_input = preprocess_input_text(input_text)\n"
      ],
      "metadata": {
        "id": "aUu7s27F6wgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform prediction using the loaded model\n",
        "predicted_probs = bilstmModel.predict(np.array([processed_input]))\n",
        "predicted_emotion_index = np.argmax(predicted_probs)\n",
        "\n",
        "predicted_emotion_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsaNcmAG84vY",
        "outputId": "36c98102-9fd3-43fa-f3f1-442a56edcfce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 38ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the predicted emotion\n",
        "predicted_emotion = enc.categories_[0][predicted_emotion_index]"
      ],
      "metadata": {
        "id": "5QUBHr3WofNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predicted Emotion:\", predicted_emotion)\n",
        "print(\"Predicted Emotion Probabilities:\", predicted_probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKJLgmXI8_5u",
        "outputId": "e64710ba-677f-4ec2-a098-ac3d2e0cd981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Emotion: joy\n",
            "Predicted Emotion Probabilities: [[0.00853515 0.01681765 0.00696166 0.00258888 0.7698855  0.16200666\n",
            "  0.03320459]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM\n",
        "\n",
        "Imagine you're reading a story, but you're reading it both forwards and backwards at the same time. That's kind of like what a Bidirectional LSTM does, but with words instead of a story.\n",
        "\n",
        "LSTM stands for Long Short-Term Memory, which is a type of neural network that's really good at understanding sequences of data, like sentences. It's used a lot in things like language translation and text generation.\n",
        "\n",
        "Now, a Bidirectional LSTM takes this idea a step further. Instead of just looking at words in one direction (like reading a sentence from start to finish), it looks at words both forwards and backwards. This helps it capture more context from the surrounding words.\n",
        "\n",
        "Imagine you're trying to understand the meaning of a word in a sentence. Sometimes the words that come after it give you a clue, and sometimes the words before it do. A Bidirectional LSTM makes sure you're not missing out on any of those clues.\n",
        "\n"
      ],
      "metadata": {
        "id": "YpUFdCfqKHFg"
      }
    }
  ]
}